{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a2386da-ba01-4a55-aa88-9b7b3bdae718",
      "metadata": {
        "id": "5a2386da-ba01-4a55-aa88-9b7b3bdae718"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel, RobertaTokenizer, RobertaModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from collections import defaultdict\n",
        "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
        "from rdflib.namespace import RDFS, OWL, XSD\n",
        "import urllib.parse\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import pytesseract\n",
        "import whisper\n",
        "from IPython.display import display, Audio, Markdown\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acfae44e-1e6c-49e9-ac66-c67dd8d6ed0b",
      "metadata": {
        "id": "acfae44e-1e6c-49e9-ac66-c67dd8d6ed0b"
      },
      "outputs": [],
      "source": [
        "# --- Cell 3: Load the Whisper Model ---\n",
        "# This will download the model weights (~142MB for 'base') the first time it's run.\n",
        "# Subsequent runs will load the cached model.\n",
        "# Other options: 'tiny', 'small', 'medium', 'large'\n",
        "model_name = \"base\"\n",
        "# print(f\"Loading Whisper model '{model_name}'...\")\n",
        "try:\n",
        "    # Using fp16=False is recommended if running on CPU for better compatibility.\n",
        "    # If you have a CUDA-enabled GPU and PyTorch with CUDA installed,\n",
        "    # Whisper will automatically try to use it, and fp16=True might be faster.\n",
        "    model = whisper.load_model(model_name)\n",
        "    # print(f\"Whisper '{model_name}' model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    # print(f\"Error loading Whisper model: {e}\")\n",
        "    # print(\"Please ensure 'openai-whisper' is installed and dependencies (like PyTorch) are met.\")\n",
        "    # Stop execution if model fails to load\n",
        "    raise SystemExit(\"Model loading failed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dd4d465-c8e9-4e8c-9b4f-00f07e415fb2",
      "metadata": {
        "id": "8dd4d465-c8e9-4e8c-9b4f-00f07e415fb2",
        "outputId": "5d211269-7d0f-420c-f415-058cbd9c9f7d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\aryand\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "072f1e3d-d93f-4c1e-a43a-5339db39e888",
      "metadata": {
        "id": "072f1e3d-d93f-4c1e-a43a-5339db39e888"
      },
      "outputs": [],
      "source": [
        "#input_text= Flavonoids, a group of natural substances with variable phenolic structures, are found in fruits, vegetables, grains, bark, roots, stems, flowers, tea and wine. These natural products are well known for their beneficial effects on health and efforts are being made to isolate the ingredients so called flavonoids. Flavonoids are now considered as an indispensable component in a variety of nutraceutical, pharmaceutical, medicinal and cosmetic applications. This is attributed to their anti-oxidative, anti-inflammatory, anti-mutagenic and anti-carcinogenic properties coupled with their capacity to modulate key cellular enzyme function. Research on flavonoids received an added impulse with the discovery of the low cardiovascular mortality rate and also prevention of CHD. Information on the working mechanisms of flavonoids is still not understood properly. However, it has widely been known for centuries that derivatives of plant origin possess a broad spectrum of biological activity. Current trends of research and development activities on flavonoids relate to isolation, identification, characterisation and functions of flavonoids and finally their applications on health benefits. Molecular docking and knowledge of bioinformatics are also being used to predict potential applications and manufacturing by industry. In the present review, attempts have been made to discuss the current trends of research and development on flavonoids, working mechanisms of flavonoids, flavonoid functions and applications, prediction of flavonoids as potential drugs in preventing chronic diseases and future research directions.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b21c747d-6f57-4aac-93bf-629a791aba71",
      "metadata": {
        "id": "b21c747d-6f57-4aac-93bf-629a791aba71",
        "outputId": "8d5e7912-40c9-414b-ee3c-b8c8722f5325"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Text/Audio Processing Tool ---\n",
            "Select input type:\n",
            "1. Image URL\n",
            "2. Image Path\n",
            "3. Direct Text Input\n",
            "4. Audio File Path\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Enter your choice (1/2/3/4):  3\n",
            "Please enter the text directly:\n",
            " Flavonoids, a group of natural substances with variable phenolic structures, are found in fruits, vegetables, grains, bark, roots, stems, flowers, tea and wine. These natural products are well known for their beneficial effects on health and efforts are being made to isolate the ingredients so called flavonoids. Flavonoids are now considered as an indispensable component in a variety of nutraceutical, pharmaceutical, medicinal and cosmetic applications. This is attributed to their anti-oxidative, anti-inflammatory, anti-mutagenic and anti-carcinogenic properties coupled with their capacity to modulate key cellular enzyme function. Research on flavonoids received an added impulse with the discovery of the low cardiovascular mortality rate and also prevention of CHD. Information on the working mechanisms of flavonoids is still not understood properly. However, it has widely been known for centuries that derivatives of plant origin possess a broad spectrum of biological activity. Current trends of research and development activities on flavonoids relate to isolation, identification, characterisation and functions of flavonoids and finally their applications on health benefits. Molecular docking and knowledge of bioinformatics are also being used to predict potential applications and manufacturing by industry. In the present review, attempts have been made to discuss the current trends of research and development on flavonoids, working mechanisms of flavonoids, flavonoid functions and applications, prediction of flavonoids as potential drugs in preventing chronic diseases and future research directions.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flavonoids, a group of natural substances with variable phenolic structures, are found in fruits, vegetables, grains, bark, roots, stems, flowers, tea and wine. These natural products are well known for their beneficial effects on health and efforts are being made to isolate the ingredients so called flavonoids. Flavonoids are now considered as an indispensable component in a variety of nutraceutical, pharmaceutical, medicinal and cosmetic applications. This is attributed to their anti-oxidative, anti-inflammatory, anti-mutagenic and anti-carcinogenic properties coupled with their capacity to modulate key cellular enzyme function. Research on flavonoids received an added impulse with the discovery of the low cardiovascular mortality rate and also prevention of CHD. Information on the working mechanisms of flavonoids is still not understood properly. However, it has widely been known for centuries that derivatives of plant origin possess a broad spectrum of biological activity. Current trends of research and development activities on flavonoids relate to isolation, identification, characterisation and functions of flavonoids and finally their applications on health benefits. Molecular docking and knowledge of bioinformatics are also being used to predict potential applications and manufacturing by industry. In the present review, attempts have been made to discuss the current trends of research and development on flavonoids, working mechanisms of flavonoids, flavonoid functions and applications, prediction of flavonoids as potential drugs in preventing chronic diseases and future research directions.\n"
          ]
        }
      ],
      "source": [
        "# --- Cell: Integrated Text/Audio Input and Processing (Clean Output) ---\n",
        "\n",
        "# --- 1. Imports ---\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import easyocr\n",
        "import os\n",
        "import time\n",
        "# Ensure Whisper is installed: pip install -U openai-whisper\n",
        "# On some systems, you might also need: sudo apt-get install ffmpeg\n",
        "try:\n",
        "    import whisper\n",
        "except ImportError:\n",
        "    print(\"‚ùå Whisper library not found. Please install it: pip install -U openai-whisper\")\n",
        "    print(\"You might also need ffmpeg: https://ffmpeg.org/download.html\")\n",
        "    whisper = None # Set to None to prevent errors later if import fails\n",
        "\n",
        "# --- 2. Model Placeholders & Configuration (Load on Demand) ---\n",
        "ocr_reader = None\n",
        "transcription_model = None\n",
        "# Specify the Whisper model name: 'tiny', 'base', 'small', 'medium', 'large'\n",
        "# 'base' is a good balance of speed and accuracy for general use.\n",
        "TRANSCRIPTION_MODEL_NAME = 'base'\n",
        "\n",
        "# --- 3. Helper Functions (Image Processing & Loading) ---\n",
        "\n",
        "def is_blurry(gray, threshold=100.0):\n",
        "    \"\"\"Check if image is blurry using the variance of the Laplacian.\"\"\"\n",
        "    try:\n",
        "        variance = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "        return variance < threshold, variance\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error calculating blurriness: {e}\")\n",
        "        return False, 0 # Assume not blurry if calculation fails\n",
        "\n",
        "def preprocess_image(img):\n",
        "    \"\"\"\n",
        "    Preprocess the image to improve OCR accuracy.\n",
        "    Steps: Convert to grayscale, check blur, apply adaptive thresholding.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        # Check for blur\n",
        "        blurry, variance = is_blurry(gray)\n",
        "        if blurry:\n",
        "            print(f\"‚ö†Ô∏è Warning: Image might be blurry (Laplacian variance = {variance:.2f}). OCR accuracy may be affected.\")\n",
        "        # Adaptive thresholding\n",
        "        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                       cv2.THRESH_BINARY, 11, 2)\n",
        "        return thresh\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during image preprocessing: {e}\")\n",
        "        return None # Return None if preprocessing fails\n",
        "\n",
        "def load_image_from_path(path):\n",
        "    \"\"\"Load image from a local file path.\"\"\"\n",
        "    img = cv2.imread(path)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Could not load image from path: {path}\")\n",
        "    return img\n",
        "\n",
        "def load_image_from_url(url):\n",
        "    \"\"\"Load image from a URL.\"\"\"\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status() # Raises an exception for bad status codes (4xx or 5xx)\n",
        "    img_pil = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "    img = np.array(img_pil)\n",
        "    # Convert from RGB (PIL) to BGR (OpenCV)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    return img\n",
        "\n",
        "# --- 4. Helper Function (Audio Transcription) ---\n",
        "\n",
        "def transcribe_audio(audio_path, model):\n",
        "    \"\"\"\n",
        "    Transcribes the audio file using the provided Whisper model.\n",
        "    Returns the transcribed text or None if an error occurs.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(audio_path):\n",
        "        print(f\"‚ùå Error: Audio file not found at '{audio_path}'\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\n‚è≥ Transcribing audio file: {os.path.basename(audio_path)}...\")\n",
        "    print(f\"   Using model: '{TRANSCRIPTION_MODEL_NAME}' (This may take time depending on audio length and model size)\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # Perform the transcription (fp16=False is generally safer for CPU)\n",
        "        result = model.transcribe(audio_path, fp16=False)\n",
        "        input_text = result['text']\n",
        "\n",
        "        end_time = time.time()\n",
        "        processing_time = end_time - start_time\n",
        "        print(f\"‚úÖ Transcription finished in {processing_time:.2f} seconds.\")\n",
        "        # We add a leading space here IF whisper provides text without it.\n",
        "        # Whisper often trims leading space, so print adds it back if needed.\n",
        "        if input_text and not input_text.startswith(' '):\n",
        "             input_text = ' ' + input_text # Add leading space if missing\n",
        "        return input_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå An error occurred during transcription: {e}\")\n",
        "        return None # Return None on transcription error\n",
        "\n",
        "# --- 5. Main Interactive Function ---\n",
        "\n",
        "def process_input():\n",
        "    \"\"\"\n",
        "    Main function to handle user input selection (Image, Text, Audio)\n",
        "    and perform the corresponding processing task.\n",
        "    \"\"\"\n",
        "    global ocr_reader, transcription_model # Allow modification of global placeholders\n",
        "    input_text = \"\" # Initialize variable to store the input/output text\n",
        "\n",
        "    # Display options\n",
        "    print(\"--- Text/Audio Processing Tool ---\")\n",
        "    print(\"Select input type:\")\n",
        "    print(\"1. Image URL\")\n",
        "    print(\"2. Image Path\")\n",
        "    print(\"3. Direct Text Input\")\n",
        "    print(\"4. Audio File Path\")\n",
        "    choice = input(\"Enter your choice (1/2/3/4): \").strip()\n",
        "\n",
        "    # --- Process Based on Choice ---\n",
        "    if choice == '1' or choice == '2':\n",
        "        # --- OCR Processing ---\n",
        "        if ocr_reader is None:\n",
        "            print(\"\\n‚è≥ Initializing EasyOCR Reader (first time)...\")\n",
        "            try:\n",
        "                # Initialize EasyOCR (English, CPU)\n",
        "                ocr_reader = easyocr.Reader(['en'], gpu=False)\n",
        "                print(\"üëç EasyOCR Reader initialized.\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error initializing EasyOCR: {e}\")\n",
        "                ocr_reader = None # Ensure it stays None if failed\n",
        "\n",
        "        if ocr_reader: # Proceed only if reader was loaded successfully\n",
        "            image_source = \"\"\n",
        "            try:\n",
        "                if choice == '1':\n",
        "                    image_source = input(\"Please enter the image URL: \").strip()\n",
        "                    img = load_image_from_url(image_source)\n",
        "                else: # choice == '2'\n",
        "                    print(\"‚ö†Ô∏è Note: OCR accuracy can vary, especially with handwriting or low quality images.\")\n",
        "                    image_source = input(\"Please enter the local file path to the image: \").strip()\n",
        "                    clean_path = image_source.strip().strip('\"').replace('/', '\\\\')\n",
        "                    img = load_image_from_path(clean_path)\n",
        "\n",
        "                print(\"‚è≥ Preprocessing image...\")\n",
        "                processed_img = preprocess_image(img)\n",
        "\n",
        "                if processed_img is not None:\n",
        "                    print(\"‚è≥ Performing OCR...\")\n",
        "                    start_time = time.time()\n",
        "                    # Use detail=0 to get only the text strings\n",
        "                    result = ocr_reader.readtext(processed_img, detail=0)\n",
        "                    end_time = time.time()\n",
        "                    print(f\"‚úÖ OCR finished in {end_time - start_time:.2f} seconds.\")\n",
        "                    input_text = \"\\n\".join(result) # Join detected text lines\n",
        "                else:\n",
        "                    print(\"‚ùå Skipping OCR due to preprocessing error.\")\n",
        "                    input_text = \"\"\n",
        "\n",
        "            except FileNotFoundError as e:\n",
        "                 print(f\"‚ùå Error: {e}\")\n",
        "                 input_text = \"\"\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                 print(f\"‚ùå Error fetching image from URL: {e}\")\n",
        "                 input_text = \"\"\n",
        "            except Exception as e:\n",
        "                 print(f\"‚ùå An unexpected error occurred during image processing: {e}\")\n",
        "                 input_text = \"\"\n",
        "        else:\n",
        "            print(\"‚ùå Cannot perform OCR because the EasyOCR reader failed to initialize.\")\n",
        "            input_text = \"\"\n",
        "\n",
        "\n",
        "    elif choice == '3':\n",
        "        # --- Direct Text Input ---\n",
        "        input_text = input(\"Please enter the text directly:\\n\")\n",
        "\n",
        "\n",
        "    elif choice == '4':\n",
        "        # --- Audio Transcription ---\n",
        "        if whisper is None:\n",
        "             print(\"‚ùå Cannot transcribe audio because the Whisper library failed to import.\")\n",
        "             input_text = \"\"\n",
        "        else:\n",
        "            if transcription_model is None:\n",
        "                print(f\"\\n‚è≥ Initializing Transcription Model '{TRANSCRIPTION_MODEL_NAME}' (first time)...\")\n",
        "                print(\"   (This might download model weights)\")\n",
        "                try:\n",
        "                    transcription_model = whisper.load_model(TRANSCRIPTION_MODEL_NAME)\n",
        "                    print(f\"üëç Whisper '{TRANSCRIPTION_MODEL_NAME}' model loaded.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Error loading transcription model: {e}\")\n",
        "                    transcription_model = None\n",
        "\n",
        "            if transcription_model: # Proceed only if model loaded\n",
        "                audio_source = input(\"Please enter the local file path to the audio file: \").strip()\n",
        "                clean_path = audio_source.strip().strip('\"').replace('/', '\\\\')\n",
        "                # Call the dedicated transcription function\n",
        "                input_text = transcribe_audio(clean_path, transcription_model)\n",
        "                if input_text is None: # Handle case where transcribe_audio indicated an error\n",
        "                     input_text = \"\"\n",
        "            else:\n",
        "                 print(\"‚ùå Cannot transcribe because the transcription model failed to load.\")\n",
        "                 input_text = \"\"\n",
        "\n",
        "    else:\n",
        "        # --- Invalid Choice ---\n",
        "        print(\"‚ùå Invalid input. Please enter 1, 2, 3, or 4.\")\n",
        "        input_text = \"\" # Ensure text is empty for invalid choice\n",
        "\n",
        "    # --- Final Output (MODIFIED) ---\n",
        "    # Only print the text if it's not empty/whitespace\n",
        "    # Keep error/empty messages for cases where no text was produced\n",
        "    if not input_text.strip():\n",
        "        # Print informative messages if no text resulted\n",
        "        if choice in ['1', '2'] and ocr_reader is not None: # Avoid printing if reader failed init\n",
        "            print(\"\\n‚ö†Ô∏è No text detected or an error occurred during OCR.\")\n",
        "        elif choice == '4' and transcription_model is not None: # Avoid printing if model failed init\n",
        "            print(\"\\n‚ö†Ô∏è No text transcribed or an error occurred during transcription.\")\n",
        "        elif choice == '3':\n",
        "             print(\"\\n‚ÑπÔ∏è No text was entered.\")\n",
        "        # Error for invalid choice 'else' already printed above\n",
        "        # Error for model/reader init failure already printed above\n",
        "    else:\n",
        "        # If text exists, print *only* the text content\n",
        "        # The leading space is handled in transcribe_audio now\n",
        "        print(input_text) # <<< This is the only print for successful output\n",
        "\n",
        "    # Still return the text, might be useful\n",
        "    return input_text\n",
        "\n",
        "# --- 6. Run the Main Function ---\n",
        "if __name__ == \"__main__\": # Standard check\n",
        "    input_text = process_input()\n",
        "    # The result is now stored in processed_text and printed cleanly above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cdb6800-3d1c-4d8d-a507-82ac5f55adae",
      "metadata": {
        "id": "6cdb6800-3d1c-4d8d-a507-82ac5f55adae"
      },
      "outputs": [],
      "source": [
        "#printing raw output from API and separated one (sepration doesnt work good)\n",
        "### Always use more tokens for better output, otherwise it might bot generate all the required field outputs ###\n",
        "\n",
        "api_key = '---------'\n",
        "\n",
        "openai.api_key = api_key\n",
        "\n",
        "# Input text for processing\n",
        "# CELL 4 - REVISED PROMPT\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an expert on Knowledge graph and Ontologies formation. Respond ONLY with the requested structured data, do not include conversational text or explanations.\"},\n",
        "    {\"role\": \"user\", \"content\": f\"\"\"From the following text: ‚Äò{input_text}‚Äô\n",
        "\n",
        "Identify triples representing factual relationships in the format [Subject, Predicate, Object].\n",
        "\n",
        "Output ONLY the triples, following this exact structure:\n",
        "1. Start the response with the line: Triples:\n",
        "2. List each triple on a new line.\n",
        "3. Each triple line MUST start with '- ' (dash and space).\n",
        "4. Each triple MUST be enclosed in exactly one pair of square brackets `[]`.\n",
        "5. Inside the brackets, the Subject, Predicate, and Object MUST be separated by a comma and a space `, `.\n",
        "\n",
        "Example format:\n",
        "Triples:\n",
        "- [Subject1, Predicate1, Object1]\n",
        "- [Subject2, Predicate2, Object2]\n",
        "\n",
        "Do NOT include any text before \"Triples:\" or after the list of triples.\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4\", # Or preferred model\n",
        "    messages=messages,\n",
        "    max_tokens=5000\n",
        ")\n",
        "\n",
        "output = response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1afb9bdf-3755-42a6-ab3f-2aec8f0908e1",
      "metadata": {
        "id": "1afb9bdf-3755-42a6-ab3f-2aec8f0908e1",
        "outputId": "a1ab1869-6dc3-4035-9ffc-16ef55511dc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully extracted 24 triples.\n",
            "[['Flavonoids', 'are found in', 'fruits'],\n",
            " ['Flavonoids', 'are found in', 'vegetables'],\n",
            " ['Flavonoids', 'are found in', 'grains'],\n",
            " ['Flavonoids', 'are found in', 'bark'],\n",
            " ['Flavonoids', 'are found in', 'roots'],\n",
            " ['Flavonoids', 'are found in', 'stems'],\n",
            " ['Flavonoids', 'are found in', 'flowers'],\n",
            " ['Flavonoids', 'are found in', 'tea'],\n",
            " ['Flavonoids', 'are found in', 'wine'],\n",
            " ['Flavonoids',\n",
            "  'are considered as',\n",
            "  'indispensable component in nutraceutical applications'],\n",
            " ['Flavonoids',\n",
            "  'are considered as',\n",
            "  'indispensable component in pharmaceutical applications'],\n",
            " ['Flavonoids',\n",
            "  'are considered as',\n",
            "  'indispensable component in medicinal applications'],\n",
            " ['Flavonoids',\n",
            "  'are considered as',\n",
            "  'indispensable component in cosmetic applications'],\n",
            " ['Flavonoids', 'have', 'anti-oxidative properties'],\n",
            " ['Flavonoids', 'have', 'anti-inflammatory properties'],\n",
            " ['Flavonoids', 'have', 'anti-mutagenic properties'],\n",
            " ['Flavonoids', 'have', 'anti-carcinogenic properties'],\n",
            " ['Flavonoids', 'have', 'capacity to modulate key cellular enzyme function'],\n",
            " ['Flavonoids', 'are known for', 'centuries for biological activity'],\n",
            " ['Research on flavonoids', 'includes', 'isolation of flavonoids'],\n",
            " ['Research on flavonoids', 'includes', 'identification of flavonoids'],\n",
            " ['Research on flavonoids', 'includes', 'characterisation of flavonoids'],\n",
            " ['Research on flavonoids', 'includes', 'studying functions of flavonoids'],\n",
            " ['Flavonoids',\n",
            "  'are predicted as',\n",
            "  'potential drugs in preventing chronic diseases']]\n"
          ]
        }
      ],
      "source": [
        "# CELL 7 - CORRECTED PARSING LOGIC\n",
        "import re\n",
        "import pprint\n",
        "\n",
        "# The 'output' variable should contain the string generated by OpenAI (from cell 4/5)\n",
        "# Example assignment if running independently:\n",
        "# output = \"\"\"\n",
        "# Sure, extracting triples from the given text could be as such:\n",
        "#\n",
        "# Triples:\n",
        "#\n",
        "# - [Flavonoids, is a group of, natural substances with variable phenolic structures]\n",
        "# ... (rest of the multiline string) ...\n",
        "# Please, note that a single sentence can provide more than one triple, as seen above.\n",
        "# \"\"\"\n",
        "\n",
        "triples_list = [] # Initialize an empty list\n",
        "in_triples_section = False\n",
        "\n",
        "# Make sure 'output' exists and is a string\n",
        "if 'output' not in locals() or not isinstance(output, str):\n",
        "    print(\"Error: 'output' variable not found or is not a string. Make sure Cell 4 ran correctly.\")\n",
        "else:\n",
        "    # Split the text into lines and process each line\n",
        "    lines = output.splitlines()\n",
        "\n",
        "    for line in lines:\n",
        "        stripped_line = line.strip()\n",
        "\n",
        "        # Find the start of the section\n",
        "        if re.match(r'^[tT]rip\\w*\\s*:', stripped_line): # Check start of line\n",
        "            in_triples_section = True\n",
        "            continue # Move to the next line after finding the header\n",
        "\n",
        "        # Stop if we leave the section (e.g., hit the note at the end or other text)\n",
        "        if in_triples_section and stripped_line and not stripped_line.startswith('- ['):\n",
        "             # print(f\"DEBUG: Potential end of triples section at line: '{stripped_line}'\") # Optional debug\n",
        "             pass # Decide if you want to break or just ignore non-matching lines\n",
        "\n",
        "        # If we are in the section and the line looks like a triple entry\n",
        "        if in_triples_section and stripped_line.startswith('- ['):\n",
        "            # Extract content within the square brackets for this line\n",
        "            match = re.search(r'\\[(.*?)\\]', stripped_line)\n",
        "            if match:\n",
        "                list_content = match.group(1).strip()\n",
        "\n",
        "                # Find the three parts within the extracted content\n",
        "                # Use re.match here because we expect the pattern from the start of list_content\n",
        "                # Be more robust to potential extra commas within elements by limiting splits\n",
        "                parts = [p.strip() for p in list_content.split(',', 2)] # Split only on first 2 commas\n",
        "\n",
        "                if len(parts) == 3:\n",
        "                    s, p, o = parts\n",
        "                    triples_list.append([s, p, o])\n",
        "                else:\n",
        "                    print(f\"Warning: Could not parse 3 elements from content: '{list_content}' in line: '{stripped_line}' (Found {len(parts)} parts)\")\n",
        "            else:\n",
        "                 print(f\"Warning: Found line starting with '- [' but couldn't extract bracket content: '{stripped_line}'\")\n",
        "\n",
        "# Ensure triples_list is defined even if parsing failed partially\n",
        "if 'triples_list' not in locals():\n",
        "     triples_list = []\n",
        "\n",
        "# Print the final list of lists\n",
        "print(f\"Successfully extracted {len(triples_list)} triples.\")\n",
        "pprint.pprint(triples_list)\n",
        "\n",
        "# You might want to assign this to a more permanent variable if needed elsewhere\n",
        "# e.g., extracted_triples = triples_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62f2b531-83ea-48eb-91aa-1266131afce6",
      "metadata": {
        "id": "62f2b531-83ea-48eb-91aa-1266131afce6",
        "outputId": "1a2e80c2-27b6-408e-e71b-8bc9cc9c2e2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique entities (26):\n",
            "['Flavonoids', 'Research on flavonoids', 'anti-carcinogenic properties',\n",
            " 'anti-inflammatory properties', 'anti-mutagenic properties',\n",
            " 'anti-oxidative properties', 'bark',\n",
            " 'capacity to modulate key cellular enzyme function',\n",
            " 'centuries for biological activity', 'characterisation of flavonoids',\n",
            " 'flowers', 'fruits', 'grains', 'identification of flavonoids',\n",
            " 'indispensable component in cosmetic applications',\n",
            " 'indispensable component in medicinal applications',\n",
            " 'indispensable component in nutraceutical applications',\n",
            " 'indispensable component in pharmaceutical applications',\n",
            " 'isolation of flavonoids', 'potential drugs in preventing chronic diseases',\n",
            " 'roots', 'stems', 'studying functions of flavonoids', 'tea', 'vegetables',\n",
            " 'wine']\n",
            "\n",
            "Unique relations (6):\n",
            "['are considered as', 'are found in', 'are known for', 'are predicted as',\n",
            " 'have', 'includes']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pprint\n",
        "\n",
        "# Make sure the triples are there\n",
        "if 'triples_list' not in globals():\n",
        "    raise NameError(\"triples_list is missing ‚Äì run the extraction cell first!\")\n",
        "\n",
        "# 1) Gather subjects & objects ‚Üí entities\n",
        "subjects = [s for s, _, _ in triples_list]\n",
        "objects  = [o for _, _, o in triples_list]\n",
        "unique_entities = sorted(set(subjects + objects))   # dedupe + sort\n",
        "\n",
        "# 2) Gather predicates ‚Üí relations\n",
        "unique_relations = sorted({p for _, p, _ in triples_list})\n",
        "\n",
        "# 3) Print nicely\n",
        "print(f\"Unique entities ({len(unique_entities)}):\")\n",
        "pprint.pprint(unique_entities, compact=True)\n",
        "print(f\"\\nUnique relations ({len(unique_relations)}):\")\n",
        "pprint.pprint(unique_relations, compact=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cce56ae-47bd-4f5a-9f79-610b4b12a4ff",
      "metadata": {
        "id": "6cce56ae-47bd-4f5a-9f79-610b4b12a4ff",
        "outputId": "d8964489-ea01-49b8-f95e-290b26e2756c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vectorised 26 entities.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\aryand\\.conda\\envs\\new_env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")    # fast, lightweight\n",
        "embeddings = {ent: model.encode(ent, show_progress_bar=False)\n",
        "              for ent in unique_entities}\n",
        "\n",
        "print(f\"Vectorised {len(embeddings)} entities.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "343de5be-ae1c-48f0-be48-67803cbe216d",
      "metadata": {
        "id": "343de5be-ae1c-48f0-be48-67803cbe216d",
        "outputId": "fd33075a-d66e-4899-98c7-1ad452c73f2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clusters found by HDBSCAN:\n",
            "Found 0 clusters (excluding noise).\n",
            "Noise points (not assigned to any cluster): (Count: 26)\n",
            "  Flavonoids\n",
            "  Research on flavonoids\n",
            "  anti-carcinogenic properties\n",
            "  anti-inflammatory properties\n",
            "  anti-mutagenic properties\n",
            "  anti-oxidative properties\n",
            "  bark\n",
            "  capacity to modulate key cellular enzyme function\n",
            "  centuries for biological activity\n",
            "  characterisation of flavonoids\n",
            "  flowers\n",
            "  fruits\n",
            "  grains\n",
            "  identification of flavonoids\n",
            "  indispensable component in cosmetic applications\n",
            "  indispensable component in medicinal applications\n",
            "  indispensable component in nutraceutical applications\n",
            "  indispensable component in pharmaceutical applications\n",
            "  isolation of flavonoids\n",
            "  potential drugs in preventing chronic diseases\n",
            "  roots\n",
            "  stems\n",
            "  studying functions of flavonoids\n",
            "  tea\n",
            "  vegetables\n",
            "  wine\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import hdbscan\n",
        "from scipy.spatial.distance import pdist, squareform # Import squareform\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Assume 'embeddings' is a dictionary mapping words to their vectors\n",
        "# Assume 'unique_entities' is a list of your unique words/items\n",
        "\n",
        "# 1) Build an array of embedding vectors (same as your code)\n",
        "embedding_array = np.vstack([embeddings[word] for word in unique_entities])\n",
        "\n",
        "# 2) Compute pairwise distances (condensed matrix)\n",
        "distances_condensed = pdist(embedding_array, metric='cosine')\n",
        "\n",
        "# *** NEW STEP: Convert condensed distance matrix to squareform (2D) ***\n",
        "distances_squareform = squareform(distances_condensed)\n",
        "# Now, distances_squareform is a 2D symmetric matrix where distances_squareform[i, j]\n",
        "# is the distance between item i and item j, and distances_squareform[i, i] = 0.\n",
        "\n",
        "# --- HDBSCAN Clustering ---\n",
        "# 3) Initialize and run HDBSCAN\n",
        "clusterer = hdbscan.HDBSCAN(metric='precomputed',\n",
        "                            min_cluster_size=5, # EXAMPLE: Adjust this value!\n",
        "                            min_samples=None,\n",
        "                            allow_single_cluster=False,\n",
        "                            gen_min_span_tree=False)\n",
        "\n",
        "# Pass the squareform distance matrix to fit_predict\n",
        "cluster_labels = clusterer.fit_predict(distances_squareform) # Use distances_squareform here\n",
        "\n",
        "# 4) Group words by their cluster label (same as before)\n",
        "cluster_dict_hdbscan = {}\n",
        "noise_words = []\n",
        "for i, lbl in enumerate(cluster_labels):\n",
        "    entity = unique_entities[i]\n",
        "    if lbl == -1:\n",
        "        noise_words.append(entity)\n",
        "        continue\n",
        "    cluster_dict_hdbscan.setdefault(lbl, []).append(entity)\n",
        "\n",
        "# 5) (Optional) Sort within each cluster (same as before)\n",
        "clusters_hdbscan_sorted = {}\n",
        "for lbl, words_in_cluster in cluster_dict_hdbscan.items():\n",
        "    if not words_in_cluster:\n",
        "        continue\n",
        "    vecs = np.vstack([embeddings[w] for w in words_in_cluster])\n",
        "    center = vecs.mean(axis=0)\n",
        "    sorted_words = sorted(\n",
        "        words_in_cluster,\n",
        "        key=lambda w: cosine_similarity(\n",
        "            embeddings[w].reshape(1, -1),\n",
        "            center.reshape(1, -1)\n",
        "        )[0][0],\n",
        "        reverse=True\n",
        "    )\n",
        "    clusters_hdbscan_sorted[f\"Cluster_{lbl}\"] = sorted_words\n",
        "\n",
        "# 6) Print clusters (same as before)\n",
        "print(\"Clusters found by HDBSCAN:\")\n",
        "num_clusters_found = len(clusters_hdbscan_sorted)\n",
        "print(f\"Found {num_clusters_found} clusters (excluding noise).\")\n",
        "\n",
        "for name, words_in_cluster in clusters_hdbscan_sorted.items():\n",
        "    print(f\"{name}: (Size: {len(words_in_cluster)})\")\n",
        "    for w in words_in_cluster:\n",
        "        print(f\"  {w}\")\n",
        "    print()\n",
        "\n",
        "# 7) (Optional) Print noise words (same as before)\n",
        "if noise_words:\n",
        "    print(f\"Noise points (not assigned to any cluster): (Count: {len(noise_words)})\")\n",
        "    for w in noise_words:\n",
        "        print(f\"  {w}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "312063d4-39e6-4c09-9927-ead344ac1737",
      "metadata": {
        "id": "312063d4-39e6-4c09-9927-ead344ac1737"
      },
      "outputs": [],
      "source": [
        "# HAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e03f3a7c-d91c-4909-8d9c-13fd9600cea6",
      "metadata": {
        "id": "e03f3a7c-d91c-4909-8d9c-13fd9600cea6",
        "outputId": "1578d0da-f827-482e-ab6b-95a4ecf08ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ embeddings_matrix shape: (26, 384)  (rows = entities, cols = vector dim)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from scipy.spatial.distance import pdist        # already used later\n",
        "from scipy.cluster.hierarchy import linkage     # <-- import was missing\n",
        "\n",
        "# 1) filter entities that really have embeddings\n",
        "entities_with_vecs = [e for e in unique_entities if e in embeddings]\n",
        "\n",
        "# 2) warn if anything was dropped\n",
        "dropped = set(unique_entities) - set(entities_with_vecs)\n",
        "if dropped:\n",
        "    print(f\"‚ö†Ô∏è  {len(dropped)} entities skipped (no vectors): {sorted(dropped)}\")\n",
        "\n",
        "# 3) build the 2-D matrix\n",
        "embeddings_matrix = np.vstack([embeddings[e] for e in entities_with_vecs])\n",
        "\n",
        "print(f\"‚úÖ embeddings_matrix shape: {embeddings_matrix.shape}  \"\n",
        "      \"(rows = entities, cols = vector dim)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51323da2-e73c-434a-bb06-ed42ed0edb2c",
      "metadata": {
        "id": "51323da2-e73c-434a-bb06-ed42ed0edb2c"
      },
      "outputs": [],
      "source": [
        "sorted_words = sorted(\n",
        "    words,\n",
        "    key=lambda w: cosine_similarity(\n",
        "        embeddings[w].reshape(1, -1),          # ‚Üê reshape here as well\n",
        "        cluster_center.reshape(1, -1)\n",
        "    )[0][0],\n",
        "    reverse=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e16388a9-4daa-4105-8dec-18ad42b02c69",
      "metadata": {
        "id": "e16388a9-4daa-4105-8dec-18ad42b02c69",
        "outputId": "1cc35f4a-bc78-4de9-9482-1fe21b2a7e14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\aryand\\.conda\\envs\\new_env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "C:\\Users\\aryand\\.conda\\envs\\new_env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "C:\\Users\\aryand\\.conda\\envs\\new_env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "C:\\Users\\aryand\\.conda\\envs\\new_env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "C:\\Users\\aryand\\.conda\\envs\\new_env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "C:\\Users\\aryand\\.conda\\envs\\new_env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "C:\\Users\\aryand\\.conda\\envs\\new_env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "C:\\Users\\aryand\\.conda\\envs\\new_env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "C:\\Users\\aryand\\.conda\\envs\\new_env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "C:\\Users\\aryand\\.conda\\envs\\new_env\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1440: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "image/png": "-------",
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The optimal number of clusters according to the elbow method is: 2\n",
            "Cluster 1  (size: 1)\n",
            "  ‚Ä¢ tea\n",
            "\n",
            "Cluster 2  (size: 1)\n",
            "  ‚Ä¢ wine\n",
            "\n",
            "Cluster 3  (size: 1)\n",
            "  ‚Ä¢ flowers\n",
            "\n",
            "Cluster 4  (size: 1)\n",
            "  ‚Ä¢ stems\n",
            "\n",
            "Cluster 5  (size: 1)\n",
            "  ‚Ä¢ fruits\n",
            "\n",
            "Cluster 6  (size: 1)\n",
            "  ‚Ä¢ vegetables\n",
            "\n",
            "Cluster 7  (size: 1)\n",
            "  ‚Ä¢ grains\n",
            "\n",
            "Cluster 8  (size: 1)\n",
            "  ‚Ä¢ roots\n",
            "\n",
            "Cluster 9  (size: 1)\n",
            "  ‚Ä¢ bark\n",
            "\n",
            "Cluster 10  (size: 2)\n",
            "  ‚Ä¢ indispensable component in pharmaceutical applications\n",
            "  ‚Ä¢ indispensable component in medicinal applications\n",
            "\n",
            "Cluster 11  (size: 1)\n",
            "  ‚Ä¢ indispensable component in nutraceutical applications\n",
            "\n",
            "Cluster 12  (size: 1)\n",
            "  ‚Ä¢ indispensable component in cosmetic applications\n",
            "\n",
            "Cluster 13  (size: 1)\n",
            "  ‚Ä¢ potential drugs in preventing chronic diseases\n",
            "\n",
            "Cluster 14  (size: 5)\n",
            "  ‚Ä¢ Research on flavonoids\n",
            "  ‚Ä¢ characterisation of flavonoids\n",
            "  ‚Ä¢ Flavonoids\n",
            "  ‚Ä¢ identification of flavonoids\n",
            "  ‚Ä¢ studying functions of flavonoids\n",
            "\n",
            "Cluster 15  (size: 1)\n",
            "  ‚Ä¢ isolation of flavonoids\n",
            "\n",
            "Cluster 16  (size: 1)\n",
            "  ‚Ä¢ anti-mutagenic properties\n",
            "\n",
            "Cluster 17  (size: 1)\n",
            "  ‚Ä¢ anti-oxidative properties\n",
            "\n",
            "Cluster 18  (size: 1)\n",
            "  ‚Ä¢ anti-carcinogenic properties\n",
            "\n",
            "Cluster 19  (size: 1)\n",
            "  ‚Ä¢ anti-inflammatory properties\n",
            "\n",
            "Cluster 20  (size: 1)\n",
            "  ‚Ä¢ capacity to modulate key cellular enzyme function\n",
            "\n",
            "Cluster 21  (size: 1)\n",
            "  ‚Ä¢ centuries for biological activity\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate the sum of squared distances for different k values\n",
        "def calculate_wcss(data):\n",
        "    wcss = []\n",
        "    max_clusters = min(10, data.shape[0] - 1)\n",
        "    for k in range(1, max_clusters + 1):\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "        kmeans.fit(data)\n",
        "        wcss.append(kmeans.inertia_)\n",
        "    return wcss\n",
        "\n",
        "# Calculate WCSS for our embeddings\n",
        "wcss = calculate_wcss(embeddings_matrix)\n",
        "\n",
        "# Plot the elbow curve\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, len(wcss)+1), wcss, marker='o')\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()\n",
        "\n",
        "# Function to find the elbow point\n",
        "def find_elbow(wcss):\n",
        "    differences = np.diff(wcss)\n",
        "    elbow = np.argmin(differences) + 2  # Add 2 because we start from 1 and diff reduces array size by 1\n",
        "    return elbow\n",
        "\n",
        "optimal_clusters = find_elbow(wcss)\n",
        "print(f\"The optimal number of clusters according to the elbow method is: {optimal_clusters}\")\n",
        "\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# --- make sure you use the SAME list that was fed to embeddings_matrix\n",
        "aligned_entities = entities_with_vecs            # <-- key change\n",
        "\n",
        "# rebuild distance matrix & linkage if not already done\n",
        "distances = pdist(embeddings_matrix, metric='cosine')\n",
        "linked    = linkage(distances, method='average')\n",
        "\n",
        "threshold = 0.2\n",
        "clusters  = fcluster(linked, t=threshold, criterion='distance')\n",
        "\n",
        "# --- build the cluster dictionary\n",
        "cluster_dict = defaultdict(list)\n",
        "for idx, lbl in enumerate(clusters):\n",
        "    cluster_dict[lbl].append(aligned_entities[idx])\n",
        "\n",
        "# --- pretty-print\n",
        "for lbl, words in sorted(cluster_dict.items()):\n",
        "    center = np.mean([embeddings[w] for w in words], axis=0)\n",
        "    words_sorted = sorted(\n",
        "        words,\n",
        "        key=lambda w: cosine_similarity(\n",
        "            embeddings[w].reshape(1, -1),\n",
        "            center.reshape(1, -1)\n",
        "        )[0, 0],\n",
        "        reverse=True\n",
        "    )\n",
        "    print(f\"Cluster {lbl}  (size: {len(words_sorted)})\")\n",
        "    for w in words_sorted:\n",
        "        print(f\"  ‚Ä¢ {w}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41697670-299b-411a-8af3-94d091530f63",
      "metadata": {
        "id": "41697670-299b-411a-8af3-94d091530f63"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}